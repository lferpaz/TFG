{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is crucial in machine learning because it allows us to find the optimal settings for the model's parameters that maximize performance. By exploring different combinations of hyperparameters, we can fine-tune the model's behavior, improve its accuracy, and prevent issues such as overfitting or underfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPUs Available: \", len(physical_devices))\n",
    "# aactiver el uso de la GPU\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')\n",
    "# liberar espacio de la memoria de la GPU\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from preprocess import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for load the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = '../data/dataset/data/CASIA2/Au/*.*'\n",
    "fake_images_path = '../data/dataset/data/CASIA2/Tp/*.*'\n",
    "image_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(filters, dropout, learning_rate, image_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator,val_generator, batch_size, epochs, learning_rate):\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    checkpoint = ModelCheckpoint('../models/model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(val_generator),\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial, X, y):\n",
    "    # Definir los hiperparámetros a optimizar\n",
    "    filters = trial.suggest_categorical('filters', [16, 32, 64])\n",
    "    dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "\n",
    "    X = np.array(X).reshape(-1, image_size[0], image_size[1], 3)\n",
    "    y = to_categorical(y, num_classes=2)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=5)\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    model = build_model(filters, dropout, learning_rate, image_size)\n",
    "    model = train_model(model, train_generator, val_generator, batch_size, epochs, learning_rate)\n",
    "\n",
    "    # Calculamos la precisión del modelo con los datos de test\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "\n",
    "    #ir guardando en tiempo real los resultados en un fichero de texto, con el encabezado de la primera iteración\n",
    "    with open('../models/results.txt', 'a') as f:\n",
    "        if trial.number == 0:\n",
    "            f.write('iteration,filters,dropout,learning_rate,accuracy\\n')\n",
    "        f.write('{},{},{},{},{}\\n'.format(trial.number, filters, dropout, learning_rate, score[1]))\n",
    "\n",
    "    #liberar la memoria de la GPU\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "    return score[1]  # Precisión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    sampler = TPESampler(seed=0)\n",
    "\n",
    "    #cargar las imágenes\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    print(\"Cargando datos de imágenes reales...\")\n",
    "    for file_path in glob.glob(real_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(0)\n",
    "    random.shuffle(X)\n",
    "    print(\"Cargando datos de imágenes falsificadas...\")\n",
    "    for file_path in glob.glob(fake_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(1)\n",
    "\n",
    "\n",
    "    n_trials = 40\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(lambda trial: objective(trial, X, y), n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "\n",
    "    print(\"Mejores hiperparámetros encontrados:\")\n",
    "    print(best_params)\n",
    "    print(\"Valor óptimo de la métrica objetivo:\")\n",
    "    print(best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

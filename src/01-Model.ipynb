{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image, ImageChops, ImageEnhance, ImageFilter, ImageOps\n",
    "from io import BytesIO\n",
    "from scipy import ndimage, fftpack\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Reshape, Concatenate, Conv2DTranspose, UpSampling2D, Input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import *\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size=(128, 128)):\n",
    "    filters =  32\n",
    "    dropout_rate = 0.25\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, val_generator, batch_size, epochs):\n",
    "    init_lr = 1e-4\n",
    "   \n",
    "    opt = Adam(learning_rate= init_lr, decay=init_lr / epochs)\n",
    "\n",
    "    model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('../models/model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=[early_stopping, checkpoint, tensorboard_callback]\n",
    "    )\n",
    "    #Obtener metricas de entrenamiento y validacion\n",
    "    train_metrics = model.evaluate(train_generator, steps=len(train_generator), verbose=0)\n",
    "    val_metrics = model.evaluate(val_generator, steps=len(val_generator), verbose=0)\n",
    "    print('Train: %.3f, %.3f' % (train_metrics[0], train_metrics[1]))\n",
    "    print('Validation: %.3f, %.3f' % (val_metrics[0], val_metrics[1]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    real_images_path = '../data/dataset/data/CASIA2/Au/*.*'\n",
    "    fake_images_path = '../data/dataset/data/CASIA2/Tp/*.*'\n",
    "    \n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    image_size = (128, 128)\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    print(\"Cargando datos de imágenes reales...\")\n",
    "    for file_path in glob.glob(real_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(0)\n",
    "\n",
    "    random.shuffle(X)\n",
    "\n",
    "    print(\"Cargando datos de imágenes falsificadas...\")\n",
    "    for file_path in glob.glob(fake_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(1)\n",
    "\n",
    "    X= np.array(X).reshape(-1, image_size[0], image_size[1], 3)\n",
    "    y = to_categorical(y, num_classes = 2)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=5)\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    model = build_model(image_size)\n",
    "    model = train_model(model, train_generator, val_generator, batch_size, epochs)\n",
    "\n",
    "    #Calculamos la presicion del modelo con los datos de entrenamiento\n",
    "    score = model.evaluate(X_train, y_train)\n",
    "    print('TRAIN loss:', score[0])\n",
    "    print('TRAIN accuracy:', score[1])\n",
    "\n",
    "    # Calculamos la precisión del modelo con los datos de test\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('TEST loss:', score[0])\n",
    "    print('TEST accuracy:', score[1])\n",
    "\n",
    "    # Guardamos el modelo\n",
    "    model.save('../models/model'+str(score[1])+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size):\n",
    "    dropout = 0.25\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=30, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(Conv2D(filters=30, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(filters=60, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=60, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos de imágenes reales...\n",
      "Cargando datos de imágenes falsificadas...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               16777728  \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,065,762\n",
      "Trainable params: 17,065,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8227\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88105, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 34s 102ms/step - loss: 0.3788 - accuracy: 0.8227 - val_loss: 0.2933 - val_accuracy: 0.8810\n",
      "Epoch 2/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.8902\n",
      "Epoch 2: val_accuracy did not improve from 0.88105\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2795 - accuracy: 0.8902 - val_loss: 0.3033 - val_accuracy: 0.8660\n",
      "Epoch 3/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9029\n",
      "Epoch 3: val_accuracy improved from 0.88105 to 0.89611, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 31s 99ms/step - loss: 0.2544 - accuracy: 0.9029 - val_loss: 0.2597 - val_accuracy: 0.8961\n",
      "Epoch 4/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.9029\n",
      "Epoch 4: val_accuracy did not improve from 0.89611\n",
      "316/316 [==============================] - 31s 96ms/step - loss: 0.2511 - accuracy: 0.9029 - val_loss: 0.2667 - val_accuracy: 0.8874\n",
      "Epoch 5/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9085\n",
      "Epoch 5: val_accuracy did not improve from 0.89611\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2395 - accuracy: 0.9085 - val_loss: 0.2668 - val_accuracy: 0.8945\n",
      "Epoch 6/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9041\n",
      "Epoch 6: val_accuracy improved from 0.89611 to 0.90008, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 31s 99ms/step - loss: 0.2440 - accuracy: 0.9041 - val_loss: 0.2509 - val_accuracy: 0.9001\n",
      "Epoch 7/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9095\n",
      "Epoch 7: val_accuracy improved from 0.90008 to 0.90642, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 31s 99ms/step - loss: 0.2353 - accuracy: 0.9095 - val_loss: 0.2412 - val_accuracy: 0.9064\n",
      "Epoch 8/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9117\n",
      "Epoch 8: val_accuracy did not improve from 0.90642\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2273 - accuracy: 0.9117 - val_loss: 0.2661 - val_accuracy: 0.8914\n",
      "Epoch 9/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9094\n",
      "Epoch 9: val_accuracy did not improve from 0.90642\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2284 - accuracy: 0.9094 - val_loss: 0.2730 - val_accuracy: 0.8850\n",
      "Epoch 10/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9121\n",
      "Epoch 10: val_accuracy did not improve from 0.90642\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2174 - accuracy: 0.9121 - val_loss: 0.2379 - val_accuracy: 0.9033\n",
      "Epoch 11/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9150\n",
      "Epoch 11: val_accuracy improved from 0.90642 to 0.90722, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 31s 99ms/step - loss: 0.2118 - accuracy: 0.9150 - val_loss: 0.2392 - val_accuracy: 0.9072\n",
      "Epoch 12/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9147\n",
      "Epoch 12: val_accuracy did not improve from 0.90722\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2093 - accuracy: 0.9147 - val_loss: 0.2384 - val_accuracy: 0.9048\n",
      "Epoch 13/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9160\n",
      "Epoch 13: val_accuracy did not improve from 0.90722\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2024 - accuracy: 0.9160 - val_loss: 0.2391 - val_accuracy: 0.9064\n",
      "Epoch 14/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9162\n",
      "Epoch 14: val_accuracy did not improve from 0.90722\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.2056 - accuracy: 0.9162 - val_loss: 0.2485 - val_accuracy: 0.9001\n",
      "Epoch 15/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9178\n",
      "Epoch 15: val_accuracy did not improve from 0.90722\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.1950 - accuracy: 0.9178 - val_loss: 0.2391 - val_accuracy: 0.9072\n",
      "Epoch 16/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9181\n",
      "Epoch 16: val_accuracy improved from 0.90722 to 0.90960, saving model to ../models\\model.h5\n",
      "316/316 [==============================] - 31s 98ms/step - loss: 0.1925 - accuracy: 0.9181 - val_loss: 0.2319 - val_accuracy: 0.9096\n",
      "Epoch 17/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9185\n",
      "Epoch 17: val_accuracy did not improve from 0.90960\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.1875 - accuracy: 0.9185 - val_loss: 0.2465 - val_accuracy: 0.9025\n",
      "Epoch 18/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9206\n",
      "Epoch 18: val_accuracy did not improve from 0.90960\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.1830 - accuracy: 0.9206 - val_loss: 0.2623 - val_accuracy: 0.9001\n",
      "Epoch 19/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.9226\n",
      "Epoch 19: val_accuracy did not improve from 0.90960\n",
      "316/316 [==============================] - 30s 96ms/step - loss: 0.1751 - accuracy: 0.9226 - val_loss: 0.2435 - val_accuracy: 0.9072\n",
      "Epoch 20/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9219\n",
      "Epoch 20: val_accuracy did not improve from 0.90960\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.1761 - accuracy: 0.9219 - val_loss: 0.2422 - val_accuracy: 0.9072\n",
      "Epoch 21/50\n",
      "316/316 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9259\n",
      "Epoch 21: val_accuracy did not improve from 0.90960\n",
      "316/316 [==============================] - 31s 97ms/step - loss: 0.1657 - accuracy: 0.9259 - val_loss: 0.2642 - val_accuracy: 0.8969\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.2059 - accuracy: 0.9255\n",
      "Test loss: 0.20590028166770935\n",
      "Test accuracy: 0.9255150556564331\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "from model import *\n",
    "from utils import *\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, MaxPooling2D, UpSampling2D, Input, Concatenate, Conv2DTranspose, BatchNormalization,Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance,ImageFilter, ImageOps\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from scipy.fftpack import dct\n",
    "from scipy import ndimage\n",
    "from scipy import fftpack\n",
    "import optuna\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def build_model(image_size=(128, 128)):\n",
    "    filters =  32\n",
    "    dropout_rate = 0.25\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_generator, val_generator, batch_size, epochs):\n",
    "    init_lr = 1e-4\n",
    "   \n",
    "    opt = Adam(learning_rate= init_lr, decay=init_lr / epochs)\n",
    "\n",
    "    model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('../models/model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=[early_stopping, checkpoint, tensorboard_callback]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    real_images_path = '../data/dataset/data/CASIA2/Au/*.*'\n",
    "    fake_images_path = '../data/dataset/data/CASIA2/Tp/*.*'\n",
    "    image_size = (128, 128)\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    image_size = (128, 128)\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    print(\"Cargando datos de imágenes reales...\")\n",
    "    for file_path in glob.glob(real_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(0)\n",
    "\n",
    "    random.shuffle(X)\n",
    "\n",
    "    print(\"Cargando datos de imágenes falsificadas...\")\n",
    "    for file_path in glob.glob(fake_images_path):\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(1)\n",
    "\n",
    "    X= np.array(X).reshape(-1, image_size[0], image_size[1], 3)\n",
    "    y = to_categorical(y, num_classes = 2)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=5)\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    model = build_model(image_size)\n",
    "    model = train_model(model, train_generator, val_generator, batch_size, epochs)\n",
    "\n",
    "    # Calculamos la precisión del modelo con los datos de test\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Guardamos el modelo\n",
    "    model.save('../models/model'+str(score[1])+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/luisp/anaconda3/envs/test/Lib/site-packages/skimage/graphviz/'''\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = load_model('../models/best_model_0.9072.h5')\n",
    "\n",
    "# Generar la representación gráfica del modelo\n",
    "plot_model(model, to_file='arquitectura_del_modelo.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

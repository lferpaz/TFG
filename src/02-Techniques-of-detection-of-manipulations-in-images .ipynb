{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques of detection of manipulations in images "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we showcase some of the techniques explored to identify modifications in images. The objective is to extract the areas from the images that are classified by the developed model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GPU: Importing a GPU can significantly enhance the performance of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from model import *\n",
    "from utils import *\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, MaxPooling2D, UpSampling2D, Input, Concatenate, Conv2DTranspose, BatchNormalization,Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance,ImageFilter, ImageOps\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from scipy.fftpack import dct\n",
    "from scipy import ndimage\n",
    "from scipy import fftpack\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images test\n",
    "images_path = '../test/*.*'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap detection using the convolutional layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function has been designed to be able to draw the area that the model has identified from the extraction of characteristics, with the aim of identifying possible modified areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image(img_path,mascara):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Dilatar las zonas detectadas para unirlas en áreas continuas\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "\n",
    "    dilated = cv2.dilate(mascara, kernel, iterations=15)\n",
    "    \n",
    "    # Calcular la distancia Euclidiana de cada píxel al contorno más cercano\n",
    "    dist_transform = cv2.distanceTransform(dilated, cv2.DIST_L2, 3)\n",
    "    dist_transform_norm = cv2.normalize(dist_transform, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Asignar un mapa de color a la imagen normalizada de distancia\n",
    "    heatmap = cv2.applyColorMap(np.uint8(dist_transform_norm*255), cv2.COLORMAP_JET)\n",
    "\n",
    "    #redimensionar la imagen para que coincida con la imagen original\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Superponer el mapa de calor a la imagen original\n",
    "    result = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['real', 'fake']\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = load_model('../models/model0.9270998239517212.h5')\n",
    "\n",
    "correct = 0\n",
    "total  = 0\n",
    "\n",
    "for image_path in glob.glob(images_path)[0:1000]:\n",
    "\n",
    "    # mostrar la imagen original\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    img_copy = img.copy()\n",
    "\n",
    "    # Preparar la imagen para el modelo\n",
    "    img = preparete_image(image_path, image_size)\n",
    "    img = np.array(img).reshape(-1, image_size[0], image_size[1], 3)\n",
    "\n",
    "    # Hacer la predicción\n",
    "    print(\"Prediccion de modelo para la imagen de prueba\")\n",
    "    y_pred = model.predict(img)\n",
    "\n",
    "    # Imprimir la predicción\n",
    "    print(\"Name of the image: {}\".format(os.path.basename(image_path)))\n",
    "    print('Class prediction: {}'.format(class_names[np.argmax(y_pred)]) + ' with probability: {}'.format(np.max(y_pred)))\n",
    "\n",
    "    #obtener la ultima capa de model.layers\n",
    "    layer_outputs = [layer.output for layer in model.layers[0:12]]\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "    activations = activation_model.predict(img)\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i, activation in enumerate(activations):\n",
    "        if len(activation.shape) == 4:\n",
    "            activation = activation[0]\n",
    "        \n",
    "            plt.subplot(1, len(activations), i+1)\n",
    "            plt.title('Layer {}'.format(i+1))\n",
    "\n",
    "            for j in range(activation.shape[-1]):\n",
    "                plt.imshow(activation[:, :, j], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #generar una mascara a partir de 5ta capa de activacion\n",
    "    mask = activations[8][0, :, :, 0]\n",
    "\n",
    "    #aplicar mascara a la img_copy\n",
    "    img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
    "    img_copy = img_copy.astype('float32') / 255\n",
    "\n",
    "    mask = cv2.resize(mask, (img_copy.shape[1], img_copy.shape[0]))\n",
    "\n",
    "    mask = cv2.merge([mask, mask, mask])\n",
    "\n",
    "    # pasar la mascara a  imagen de 3 canales\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Aplicar umbralización\n",
    "    _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Encontrar contornos en la máscara binaria\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    \n",
    "    resultado = map_image(image_path, gray_mask)\n",
    "\n",
    "    # Mostrar las 3 imágenes\n",
    "    plt.figure(figsize=(10, 40))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_copy)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')  # Quita los ejes numéricos\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(resultado, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Class prediction: {}'.format(class_names[np.argmax(y_pred)]) + ' with probability: {:.2%}'.format(np.max(y_pred)))\n",
    "    plt.axis('off')  # Quita los ejes numéricos\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap by pixel distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to detect modified areas in an image by analyzing the pixel variation. By highlighting areas with significant pixel differences, we can identify possible modified areas in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_by_pixels(img_path):\n",
    "    # Leer la imagen\n",
    "    img = cv2.imread(img_path)\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calcular la diferencia entre píxeles adyacentes pixel by pixel\n",
    "    diff = cv2.absdiff(gray[:-1,:-1], gray[1:,1:])\n",
    "\n",
    "    # Aplicar un umbral para determinar las zonas con cambios significativos\n",
    "    thresh = cv2.threshold(diff, 130, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Dilatar las zonas detectadas para unirlas en áreas continuas\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=15)\n",
    "    \n",
    "    # Encontrar los contornos de las zonas detectadas\n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calcular la distancia Euclidiana de cada píxel al contorno más cercano\n",
    "    dist_transform = cv2.distanceTransform(dilated, cv2.DIST_L2, 3)\n",
    "    dist_transform_norm = cv2.normalize(dist_transform, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Asignar un mapa de color a la imagen normalizada de distancia\n",
    "    heatmap = cv2.applyColorMap(np.uint8(dist_transform_norm*255), cv2.COLORMAP_JET)\n",
    "\n",
    "    #redimensionar la imagen para que coincida con la imagen original\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Superponer el mapa de calor a la imagen original\n",
    "    result = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for file_path in glob.glob(images_path):\n",
    "        #mostrar la imagen original y la imagen con el mapa de calor con plt\n",
    "        plt.figure(figsize=(10,40))\n",
    "        plt.subplot(1,2,1)\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #quitar numeros de los ejes\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1,2,2)\n",
    "        #quitar numeros de los ejes\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.imshow((cv2.cvtColor(heatmap_by_pixels(file_path), cv2.COLOR_BGR2RGB)))\n",
    "        plt.title(\"Mapa de calor por distribución de píxeles\")\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG (Histogram of Oriented Gradients) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function utilizes the Histogram of Oriented Gradients (HOG) to divide the image into sections and analyze variations. The purpose is to identify areas with higher variation and detect possible modified zones in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hog(image_path):\n",
    "    # Cargar la imagen\n",
    "    image = cv2.imread(image_path)\n",
    "    #pasar la imagen a array\n",
    "    image = np.array(image)\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Calcular el HOG\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog_features = hog.compute(gray)\n",
    "    # Normalizar los valores del HOG\n",
    "    hog_features = hog_features.flatten()\n",
    "    hog_features /= np.linalg.norm(hog_features)\n",
    "    return hog_features\n",
    "\n",
    "\n",
    "def calculate_nad(image1, image2):\n",
    "    # Convertir las imágenes a escala de grises\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "    # Calcular la diferencia absoluta normalizada\n",
    "    diff = np.abs(gray1.astype(np.float32) - gray2.astype(np.float32))\n",
    "    diff /= 255.0\n",
    "    return diff\n",
    "\n",
    "\n",
    "def histogram_analysis(image_path, num_regions=4,vertical=False):\n",
    "    # Cargar la imagen en escala de grises\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    # Dividir la imagen en regiones de interés\n",
    "    height, width = image.shape[:2]\n",
    "    region_width = width // num_regions\n",
    "    region_height = height // num_regions\n",
    "    regions = []\n",
    "\n",
    "    if vertical:\n",
    "        for i in range(num_regions):\n",
    "            start_x = i * region_width\n",
    "            end_x = start_x + region_width\n",
    "            region = image[:, start_x:end_x]\n",
    "            regions.append(region)\n",
    "    else:\n",
    "\n",
    "        for i in range(num_regions):\n",
    "                start_y = i * region_height\n",
    "                end_y = start_y + region_height\n",
    "                region = image[start_y:end_y, :]\n",
    "                regions.append(region)\n",
    "\n",
    "    # Calcular los histogramas de las regiones\n",
    "    histograms = [cv2.calcHist([region], [0], None, [256], [0, 256]) for region in regions]\n",
    "\n",
    "    # Calcular las diferencias entre los histogramas\n",
    "    differences = []\n",
    "\n",
    "    for i in range(len(histograms) - 1):\n",
    "        diff = cv2.compareHist(histograms[i], histograms[i+1], cv2.HISTCMP_CHISQR)\n",
    "        differences.append(diff)\n",
    "\n",
    "    return differences, regions\n",
    "\n",
    "test_images_path = \"../tests/*.*\"\n",
    "\n",
    "for file_path in glob.glob(test_images_path):\n",
    "    print(\"Hog de la imagen {}\".format(file_path))\n",
    "    hog_features = calculate_hog(file_path)\n",
    "    print(hog_features)\n",
    "    \n",
    "    print(\"Analizando la imagen {}\".format(file_path))\n",
    "    differences , regions = histogram_analysis(file_path, num_regions=4, vertical=True)\n",
    "    for i, diff in enumerate(differences):\n",
    "        print(\"Diferencia entre regiones {} y {}: {}\".format(i, i+1, diff))\n",
    "    print(\"Diferencia total: {}\".format(sum(differences)))\n",
    "    # print de la región con mayor diferencia\n",
    "    print(\"La región con mayor diferencia es la región es entre la región {} y la región {}\".format(np.argmax(differences), np.argmax(differences) + 1))\n",
    "\n",
    "    #mostrar la región con mayor diferencia entre la región 1 y la región 2\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.imshow(regions[np.argmax(differences)], cmap=\"gray\")\n",
    "    plt.title(\"Región {}\".format(np.argmax(differences)))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(regions[np.argmax(differences) + 1], cmap=\"gray\")\n",
    "    plt.title(\"Región {}\".format(np.argmax(differences) + 1))\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Gradient "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code identifies areas in an image that exhibit high variation in local gradients. This can be useful for detecting edges or regions with abrupt intensity changes, such as object boundaries or shadow transitions in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_gradient_analysis(image_path):\n",
    "    # Cargar la imagen en escala de grises\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    # Calcular los gradientes locales utilizando el operador de Sobel\n",
    "    gradient_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gradient_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Calcular las magnitudes y las direcciones de los gradientes\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "    gradient_direction = np.arctan2(gradient_y, gradient_x)\n",
    "\n",
    "    # Aplicar umbralización para resaltar las áreas de alta variación de gradientes\n",
    "    threshold = np.mean(gradient_magnitude) + np.std(gradient_magnitude)\n",
    "    gradient_mask = gradient_magnitude > threshold\n",
    "\n",
    "    return gradient_mask\n",
    "\n",
    "\n",
    "test_images_path = '../tests/*.*'\n",
    "\n",
    "\n",
    "for file_path in glob.glob(test_images_path):\n",
    "    img_local_gradient = local_gradient_analysis(file_path)\n",
    "\n",
    "    # visualizar la imagen\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original\")\n",
    "    plt.subplot(1,2,2)\n",
    "    img_local_gradient = cv2.cvtColor(img_local_gradient.astype(np.uint8) * 255, cv2.COLOR_GRAY2RGB)\n",
    "    plt.imshow(img_local_gradient)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Gradiente local\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_change_detection(image_path):\n",
    "    # Cargar la imagen en escala de grises\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    # Aplicar un umbral para obtener una máscara binaria de las sombras\n",
    "    _, binary_mask = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Aplicar una transformada de Hough para detectar líneas en la máscara binaria\n",
    "    lines = cv2.HoughLinesP(binary_mask, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)\n",
    "\n",
    "    # Calcular la dirección promedio de las sombras\n",
    "    if lines is not None:\n",
    "        angles = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.arctan2(y2 - y1, x2 - x1)\n",
    "            angles.append(angle)\n",
    "\n",
    "        average_angle = np.mean(angles)\n",
    "    else:\n",
    "        average_angle = None\n",
    "        \n",
    "    return average_angle\n",
    "\n",
    "test_images_path = '../tests/*.*'\n",
    "\n",
    "\n",
    "for file_path in glob.glob(test_images_path):\n",
    "    average_shadow_angle = shadow_change_detection(file_path)\n",
    "\n",
    "    # visualizar la imagen\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original\")\n",
    "    # poner el resultado en la imagen\n",
    "    if average_shadow_angle is not None:\n",
    "        plt.text(5, 350, \"Ángulo promedio de la sombra: {:.2f}\".format(average_shadow_angle), fontsize=14, color=\"red\")\n",
    "    plt.subplot(1,2,2)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Resultado\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_analysis(image_path):\n",
    "    # Cargar la imagen en formato BGR\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convertir la imagen a diferentes espacios de color\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Mostrar la imagen en diferentes espacios de color\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"RGB\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(image_hsv)\n",
    "    plt.title(\"HSV\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image_lab)\n",
    "    plt.title(\"LAB\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Calcular características relacionadas con el color\n",
    "    rgb_mean = np.mean(image_rgb, axis=(0, 1))\n",
    "    hsv_mean = np.mean(image_hsv, axis=(0, 1))\n",
    "    lab_mean = np.mean(image_lab, axis=(0, 1))\n",
    "\n",
    "    # Mostrar las características calculadas\n",
    "    print(\"RGB Mean: \", rgb_mean)\n",
    "    print(\"HSV Mean: \", hsv_mean)\n",
    "    print(\"LAB Mean: \", lab_mean)\n",
    "\n",
    "test_images_path = '../tests/*.*'\n",
    "\n",
    "for file_path in glob.glob(test_images_path):\n",
    "    color_analysis(file_path)\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lighting Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lighting_inconsistency_detection(image_path, num_regions=4, threshold=150,vertical=True):\n",
    "    # Cargar la imagen en escala de grises\n",
    "    image = cv2.imread(image_path, 0)\n",
    "\n",
    "    img_original = cv2.imread(image_path)\n",
    "    # Dividir la imagen utilizando ventanas deslizantes, por ejemplo dividir la imagen en 8 cuadros distintos de igual tamaño (8x8)\n",
    "    regions = []\n",
    "    height, width = image.shape\n",
    "    region_height = int(height / num_regions)\n",
    "    region_width = int(width / num_regions)\n",
    "\n",
    "    for i in range(num_regions):\n",
    "        for j in range(num_regions):\n",
    "            region = image[i * region_height:(i + 1) * region_height, j * region_width:(j + 1) * region_width]\n",
    "            regions.append(region)\n",
    "\n",
    "    # Calcular la varianza de cada región\n",
    "    variances = []\n",
    "    for region in regions:\n",
    "        variances.append(np.var(region))\n",
    "\n",
    "    # Calcular la varianza promedio\n",
    "    mean_variance = np.mean(variances)\n",
    "\n",
    "    # Detectar las regiones con inconsistencias de iluminación\n",
    "    inconsistent_regions = []\n",
    "    for i, variance in enumerate(variances):\n",
    "        if variance > mean_variance + threshold:\n",
    "            inconsistent_regions.append(i)\n",
    "\n",
    "    # Visualizar las regiones con inconsistencias de iluminación\n",
    "    for i, region in enumerate(regions):\n",
    "        if i in inconsistent_regions:\n",
    "            print(\"Región {} con inconsistencia de iluminación\".format(i))\n",
    "            # Obtener las posiciones de la región en la imagen original\n",
    "            x = (i % num_regions) * region_width\n",
    "            y = int(i / num_regions) * region_height\n",
    "            # Dibujar un rectángulo en la imagen original\n",
    "            cv2.rectangle(img_original, (x, y), (x + region_width, y + region_height), (0, 0, 255), 2)\n",
    "\n",
    "    # Visualizar la imagen original\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    #mostrar la imagen original en color\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    #mostrar la imagen original con los rectángulos\n",
    "    img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "    #quitar numeros de los ejes\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_original)\n",
    "    plt.title(\"Resultado\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    return inconsistent_regions, regions\n",
    "\n",
    "for file_path in glob.glob(test_images_path):\n",
    "    inconsistent_regions, regions = lighting_inconsistency_detection(file_path, num_regions=4, threshold=300)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GPU: Importing a GPU can significantly enhance the performance of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "from model import *\n",
    "from utils import *\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, MaxPooling2D, UpSampling2D, Input, Concatenate, Conv2DTranspose, BatchNormalization,Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from PIL import Image, ImageChops, ImageEnhance,ImageFilter, ImageOps\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from scipy.fftpack import dct\n",
    "from scipy import ndimage\n",
    "from scipy import fftpack\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = '../data/dataset/data/CASIA2/Au/*.*'\n",
    "fake_images_path = '../data/dataset/data/CASIA2/Tp/*.*'\n",
    "image_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_size=(128, 128)):\n",
    "\n",
    "    filters =  32\n",
    "    dropout_rate = 0.25\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=2*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=4*filters, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_generator, val_generator, batch_size, epochs):\n",
    "    init_lr = 1e-4\n",
    "   \n",
    "    opt = Adam(learning_rate= init_lr, decay=init_lr / epochs)\n",
    "\n",
    "    model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    checkpoint = ModelCheckpoint('../models/model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    print(\"Cargando datos de imágenes reales...\")\n",
    "    for file_path in glob.glob(real_images_path)[0:100]:\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(0)\n",
    "\n",
    "    random.shuffle(X)\n",
    "\n",
    "    print(\"Cargando datos de imágenes falsificadas...\")\n",
    "    for file_path in glob.glob(fake_images_path)[0:100]:\n",
    "        X.append(preparete_image_ela(file_path, image_size))\n",
    "        y.append(1)\n",
    "\n",
    "    X = np.array(X).reshape(-1, image_size[0], image_size[1], 3)\n",
    "    y = np.array(y)\n",
    "    y = to_categorical(y, num_classes=2)  # Convertir las etiquetas a one-hot encoding\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=5)\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size)\n",
    "    val_generator = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    # Aplicar validación cruzada\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "    cvscores = []\n",
    "    metrics = []\n",
    "    for train, test in kfold.split(X, y):\n",
    "        model = build_model(image_size)\n",
    "        model = train_model(model, train_generator, val_generator, batch_size, epochs)\n",
    "        scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "        metrics.append(model.metrics_names[1])\n",
    "        cvscores.append(scores[1] * 100)\n",
    "\n",
    "\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "    for metric in metrics:\n",
    "        print(metric)\n",
    "\n",
    "\n",
    "\n",
    "    # graficar en base al score de cada validación cruzada  poner las dos lineas, cvscores y metrics\n",
    "    plt.plot(cvscores)\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Validation number')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    for i in range(0, len(cvscores)):\n",
    "        print(\"Validación cruzada: \", i, \" Accuracy: \", cvscores[i])\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
